{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iMDB_text_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQ6zSo9SYM3_"
      },
      "source": [
        "# Common imports\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe73uMKJDx7E"
      },
      "source": [
        "# TensorFlow â‰¥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcDCcjjoDUQE"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDi8ajRIaiRd",
        "outputId": "b1959a4a-e9a6-4f9b-cea7-a58cd1dd7128",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "(X_train, y_test), (X_valid, y_valid) = keras.datasets.imdb.load_data()\n",
        "X_train.shape, y_test.shape, X_valid.shape, y_valid.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25000,), (25000,), (25000,), (25000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVORWNpjd-c1",
        "outputId": "57dadc22-edd3-4f25-cf56-c2a63bc2d006",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train[0][:10]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eau4mUR_qlfC",
        "outputId": "0852dac6-de6d-4f4f-b5ad-681a9d1684a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "word_index = keras.datasets.imdb.get_word_index()\n",
        "\n",
        "# The integers 0, 1, and 2 are special: they represent the padding token, the start-of-sequence (SoS) and unknown words\n",
        "id_to_word = {id_ + 3: word for word, id_ in word_index.items()}\n",
        "for id_, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
        "    id_to_word[id_] = token\n",
        "\" \".join([id_to_word[id_] for id_ in X_train[0][:10]])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<sos> this film was just brilliant casting location scenery story'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaEenYkJq4xS"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "# as_supervised: if True, the returned tf.data.Dataset will have a 2-tuple structure (input, label)\n",
        "# with_info: if True, tfds.load will return the tuple (tf.data.Dataset, tfds.core.DatasetInfo) containing the info associated with the builder.\n",
        "datasets, info = tfds.load(\"imdb_reviews\", as_supervised=True, with_info=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNC785MXq8xh",
        "outputId": "d7374a7c-ca24-4917-efa3-0bbbf75e6c1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "datasets.keys()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['test', 'train', 'unsupervised'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4zolUZOrdvb",
        "outputId": "74aa2f8b-2e83-4360-841a-ad0078092653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        }
      },
      "source": [
        "info"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tfds.core.DatasetInfo(\n",
              "    name='imdb_reviews',\n",
              "    version=1.0.0,\n",
              "    description='Large Movie Review Dataset.\n",
              "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.',\n",
              "    homepage='http://ai.stanford.edu/~amaas/data/sentiment/',\n",
              "    features=FeaturesDict({\n",
              "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
              "        'text': Text(shape=(), dtype=tf.string),\n",
              "    }),\n",
              "    total_num_examples=100000,\n",
              "    splits={\n",
              "        'test': 25000,\n",
              "        'train': 25000,\n",
              "        'unsupervised': 50000,\n",
              "    },\n",
              "    supervised_keys=('text', 'label'),\n",
              "    citation=\"\"\"@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
              "      author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
              "      title     = {Learning Word Vectors for Sentiment Analysis},\n",
              "      booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
              "      month     = {June},\n",
              "      year      = {2011},\n",
              "      address   = {Portland, Oregon, USA},\n",
              "      publisher = {Association for Computational Linguistics},\n",
              "      pages     = {142--150},\n",
              "      url       = {http://www.aclweb.org/anthology/P11-1015}\n",
              "    }\"\"\",\n",
              "    redistribution_info=,\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqAQlHFvrg0j"
      },
      "source": [
        "train_size = info.splits[\"train\"].num_examples\n",
        "test_size = info.splits[\"test\"].num_examples"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-auryolmrtXi",
        "outputId": "aa3a7672-1410-4351-d29b-c07982191a5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_size, test_size"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 25000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1lRNFQUruYi",
        "outputId": "30196a76-240c-490b-f215-61a34c27de64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "for X_batch, y_batch in datasets[\"train\"].batch(5).take(1):\n",
        "    for review, label in zip(X_batch.numpy(), y_batch.numpy()):\n",
        "        print(\"Review:\", review.decode(\"utf-8\")[:200], \"...\")\n",
        "        print(\"Label:\", label, \"= Positive\" if label else \"= Negative\")\n",
        "        print()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review: This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting  ...\n",
            "Label: 0 = Negative\n",
            "\n",
            "Review: I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However  ...\n",
            "Label: 0 = Negative\n",
            "\n",
            "Review: Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they always seem to do. <br /><br />But come on Hollywood - a Moun ...\n",
            "Label: 0 = Negative\n",
            "\n",
            "Review: This is the kind of film for a snowy Sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm-chair and mellow for a couple of hours. Wonderful perf ...\n",
            "Label: 1 = Positive\n",
            "\n",
            "Review: As others have mentioned, all the women that go nude in this film are mostly absolutely gorgeous. The plot very ably shows the hypocrisy of the female libido. When men are around they want to be pursu ...\n",
            "Label: 1 = Positive\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd8mIPuar02y"
      },
      "source": [
        "def preprocess(X_batch, y_batch):\n",
        "    X_batch = tf.strings.substr(X_batch, 0, 300)\n",
        "    X_batch = tf.strings.regex_replace(X_batch, rb\"<br\\s*/?>\", b\" \")\n",
        "    X_batch = tf.strings.regex_replace(X_batch, b\"[^a-zA-Z']\", b\" \")\n",
        "    X_batch = tf.strings.split(X_batch)\n",
        "    return X_batch.to_tensor(default_value=b\"<pad>\"), y_batch"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMjYkWW5snqr",
        "outputId": "54e9170c-a482-4e4b-ab22-6c202bce98b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        }
      },
      "source": [
        "preprocess(X_batch, y_batch)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(5, 59), dtype=string, numpy=\n",
              " array([[b'This', b'was', b'an', b'absolutely', b'terrible', b'movie',\n",
              "         b\"Don't\", b'be', b'lured', b'in', b'by', b'Christopher',\n",
              "         b'Walken', b'or', b'Michael', b'Ironside', b'Both', b'are',\n",
              "         b'great', b'actors', b'but', b'this', b'must', b'simply', b'be',\n",
              "         b'their', b'worst', b'role', b'in', b'history', b'Even',\n",
              "         b'their', b'great', b'acting', b'could', b'not', b'redeem',\n",
              "         b'this', b\"movie's\", b'ridiculous', b'storyline', b'This',\n",
              "         b'movie', b'is', b'an', b'early', b'nineties', b'US',\n",
              "         b'propaganda', b'pi', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
              "         b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>'],\n",
              "        [b'I', b'have', b'been', b'known', b'to', b'fall', b'asleep',\n",
              "         b'during', b'films', b'but', b'this', b'is', b'usually', b'due',\n",
              "         b'to', b'a', b'combination', b'of', b'things', b'including',\n",
              "         b'really', b'tired', b'being', b'warm', b'and', b'comfortable',\n",
              "         b'on', b'the', b'sette', b'and', b'having', b'just', b'eaten',\n",
              "         b'a', b'lot', b'However', b'on', b'this', b'occasion', b'I',\n",
              "         b'fell', b'asleep', b'because', b'the', b'film', b'was',\n",
              "         b'rubbish', b'The', b'plot', b'development', b'was', b'constant',\n",
              "         b'Cons', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
              "         b'<pad>'],\n",
              "        [b'Mann', b'photographs', b'the', b'Alberta', b'Rocky',\n",
              "         b'Mountains', b'in', b'a', b'superb', b'fashion', b'and',\n",
              "         b'Jimmy', b'Stewart', b'and', b'Walter', b'Brennan', b'give',\n",
              "         b'enjoyable', b'performances', b'as', b'they', b'always',\n",
              "         b'seem', b'to', b'do', b'But', b'come', b'on', b'Hollywood',\n",
              "         b'a', b'Mountie', b'telling', b'the', b'people', b'of',\n",
              "         b'Dawson', b'City', b'Yukon', b'to', b'elect', b'themselves',\n",
              "         b'a', b'marshal', b'yes', b'a', b'marshal', b'and', b'to', b'e',\n",
              "         b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
              "         b'<pad>', b'<pad>', b'<pad>', b'<pad>'],\n",
              "        [b'This', b'is', b'the', b'kind', b'of', b'film', b'for', b'a',\n",
              "         b'snowy', b'Sunday', b'afternoon', b'when', b'the', b'rest',\n",
              "         b'of', b'the', b'world', b'can', b'go', b'ahead', b'with',\n",
              "         b'its', b'own', b'business', b'as', b'you', b'descend', b'into',\n",
              "         b'a', b'big', b'arm', b'chair', b'and', b'mellow', b'for', b'a',\n",
              "         b'couple', b'of', b'hours', b'Wonderful', b'performances',\n",
              "         b'from', b'Cher', b'and', b'Nicolas', b'Cage', b'as', b'always',\n",
              "         b'gently', b'row', b'the', b'plot', b'along', b'There', b'are',\n",
              "         b'no', b'rapids', b'to', b'cr'],\n",
              "        [b'As', b'others', b'have', b'mentioned', b'all', b'the',\n",
              "         b'women', b'that', b'go', b'nude', b'in', b'this', b'film',\n",
              "         b'are', b'mostly', b'absolutely', b'gorgeous', b'The', b'plot',\n",
              "         b'very', b'ably', b'shows', b'the', b'hypocrisy', b'of', b'the',\n",
              "         b'female', b'libido', b'When', b'men', b'are', b'around',\n",
              "         b'they', b'want', b'to', b'be', b'pursued', b'but', b'when',\n",
              "         b'no', b'men', b'are', b'around', b'they', b'become', b'the',\n",
              "         b'pursuers', b'of', b'a', b'year', b'old', b'boy', b'And',\n",
              "         b'the', b'boy', b'becomes', b'<pad>', b'<pad>', b'<pad>']],\n",
              "       dtype=object)>,\n",
              " <tf.Tensor: shape=(5,), dtype=int64, numpy=array([0, 0, 0, 1, 1])>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BinySTqssqsj"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "vocabulary = Counter()\n",
        "for X_batch, y_batch in datasets[\"train\"].batch(32).map(preprocess):\n",
        "    for review in X_batch:\n",
        "        vocabulary.update(list(review.numpy()))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5TxII17s5my",
        "outputId": "e33e86b7-e208-4ad3-ed41-5da3f68097b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vocabulary.most_common()[:3]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(b'<pad>', 214309), (b'the', 61137), (b'a', 38564)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmfhME2t5ex2",
        "outputId": "20a9ee7a-6cdb-4b59-a764-bfdd211f78d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(vocabulary)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53893"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_8e1Uf1s86L"
      },
      "source": [
        "vocab_size = 10000\n",
        "truncated_vocabulary = [\n",
        "    word for word, count in vocabulary.most_common()[:vocab_size]]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a3RHy_Js_ir",
        "outputId": "7aeb3beb-7e20-4f20-881d-c8b06afb8897",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "word_to_id = {word: index for index, word in enumerate(truncated_vocabulary)}\n",
        "for word in b\"This movie was awesoommmee\".split():\n",
        "    print(word_to_id.get(word) or vocab_size)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22\n",
            "12\n",
            "11\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSf54O8ztEO7"
      },
      "source": [
        "words = tf.constant(truncated_vocabulary)\n",
        "word_ids = tf.range(len(truncated_vocabulary), dtype=tf.int64)\n",
        "vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
        "num_oov_buckets = 1000\n",
        "table = tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8W143WBtMfj",
        "outputId": "84ab87ae-9751-4d7b-c9ba-36543779b81b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "table.lookup(tf.constant([b\"This movie was awesoommmee\".split()]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 4), dtype=int64, numpy=array([[   22,    12,    11, 10429]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5ukOg3BKfTp",
        "outputId": "17b5858a-b386-4c8e-b00e-40123d63ff69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_batch"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(8, 60), dtype=string, numpy=\n",
              "array([[b'Red', b'Eye', b'is', b'not', b'the', b'kind', b'of', b'movie',\n",
              "        b\"that's\", b'going', b'to', b'win', b'the', b'Palme', b\"D'or\",\n",
              "        b'but', b'Wes', b'Craven', b'has', b'never', b'been', b'that',\n",
              "        b'kind', b'of', b'director', b'anyway', b'and', b'his',\n",
              "        b'branding', b'is', b'a', b'good', b'indication', b'of', b'what',\n",
              "        b'a', b'film', b'goer', b'can', b'expect', b'The', b'fact',\n",
              "        b'that', b'Red', b'Eye', b'is', b'a', b'tight', b'little',\n",
              "        b'undemanding', b'package', b'at', b'minutes', b'is', b'part',\n",
              "        b'of', b'its', b'<pad>', b'<pad>', b'<pad>'],\n",
              "       [b'What', b'is', b'left', b'of', b'Planet', b'Earth', b'is',\n",
              "        b'populated', b'by', b'a', b'few', b'poor', b'and', b'starving',\n",
              "        b'rag', b'tag', b'survivors', b'They', b'must', b'eat', b'bugs',\n",
              "        b'and', b'insects', b'or', b'whatever', b'after', b'a',\n",
              "        b'poison', b'war', b'or', b'something', b'has', b'nearly',\n",
              "        b'wiped', b'out', b'all', b'human', b'civilization', b'In',\n",
              "        b'these', b'dark', b'times', b'one', b'of', b'the', b'few',\n",
              "        b'people', b'on', b'Earth', b'still', b'able', b'to', b'live',\n",
              "        b'in', b'co', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>'],\n",
              "       [b'The', b'last', b'Tarzan', b'film', b'starring', b'Johnny',\n",
              "        b'Weissmuller', b'looking', b'surprisingly', b'aged', b'a',\n",
              "        b'year', b'after', b'Tarzan', b'and', b'the', b'Huntress', b'is',\n",
              "        b'bad', b'in', b'spite', b'of', b'all', b'the', b'trivia',\n",
              "        b'one', b'can', b'add', b'to', b'make', b'it', b'look',\n",
              "        b'better', b'It', b'is', b'obvious', b'that', b'RKO', b'tried',\n",
              "        b'to', b'make', b'a', b'great', b'farewell', b'for',\n",
              "        b'Weissmuller', b'shooting', b'in', b'beautiful', b'scenery',\n",
              "        b'in', b'M', b'xico', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
              "        b'<pad>', b'<pad>', b'<pad>'],\n",
              "       [b'I', b'have', b'a', b'severe', b'problem', b'with', b'this',\n",
              "        b'show', b'several', b'actually', b'A', b'simple', b'list',\n",
              "        b'will', b'suffice', b'for', b'now', b\"I'll\", b'go', b'into',\n",
              "        b'more', b'depth', b'later', b'on', b'superficial',\n",
              "        b'characters', b'a', b'laugh', b'track', b'and', b'boring',\n",
              "        b'humour', b'If', b'you', b\"don't\", b'wish', b'to', b'look',\n",
              "        b'at', b'the', b'rest', b'of', b'this', b'review', b'and',\n",
              "        b'are', b'only', b'reading', b'it', b'so', b'you', b'can',\n",
              "        b'feel', b'superior', b'a', b'<pad>', b'<pad>', b'<pad>',\n",
              "        b'<pad>', b'<pad>'],\n",
              "       [b'The', b'year', b'is', b'Ernesto', b'Che', b'Guevara',\n",
              "        b'having', b'been', b'a', b'Cuban', b'citizen', b'for', b'the',\n",
              "        b'last', b'five', b'years', b'disappears', b'from', b'the',\n",
              "        b'face', b'of', b'the', b'Earth', b'leaving', b'a', b'glum',\n",
              "        b'Fidel', b'Castro', b'to', b'announce', b'that', b'he', b'is',\n",
              "        b'probably', b'dead', b'when', b'in', b'truth', b'he', b'has',\n",
              "        b'left', b'Cuba', b'to', b'move', b'to', b'Bolivia', b'to',\n",
              "        b'live', b'an', b'assumed', b'identity', b'Whilst', b'living',\n",
              "        b'in', b'La', b'Paz', b'<pad>', b'<pad>', b'<pad>', b'<pad>'],\n",
              "       [b'Okay', b'So', b'I', b'just', b'got', b'back', b'Before', b'I',\n",
              "        b'start', b'my', b'review', b'let', b'me', b'tell', b'you',\n",
              "        b'one', b'thing', b'I', b'wanted', b'to', b'like', b'this',\n",
              "        b'movie', b'I', b'know', b\"I've\", b'been', b'negative', b'in',\n",
              "        b'the', b'past', b'but', b'I', b'was', b'hoping', b'to', b'be',\n",
              "        b'surprised', b'and', b'actually', b'come', b'out', b'liking',\n",
              "        b'the', b'film', b'I', b\"didn't\", b\"It's\", b'not', b'just',\n",
              "        b'the', b'fact', b'that', b'every', b'horror', b'clich',\n",
              "        b'imaginable', b'<pad>', b'<pad>', b'<pad>'],\n",
              "       [b'When', b'I', b'saw', b'this', b'trailer', b'on', b'TV', b'I',\n",
              "        b'was', b'surprised', b'In', b'May', b'of', b'I', b'was', b'at',\n",
              "        b'Six', b'Flags', b'in', b'New', b'Jersey', b'and', b'this',\n",
              "        b'was', b'showing', b'at', b'a', b'D', b'attraction', b'you',\n",
              "        b'know', b'the', b'attraction', b'that', b'the', b'seats',\n",
              "        b'move', b'I', b'take', b'it', b'that', b'the', b'version', b'I',\n",
              "        b'saw', b'was', b'a', b'shortened', b'version', b'min', b'and',\n",
              "        b'also', b're', b'created', b'to', b'add', b'the', b'motion',\n",
              "        b'effects', b'It'],\n",
              "       [b'First', b'of', b'all', b'Riget', b'is', b'wonderful', b'Good',\n",
              "        b'comedy', b'and', b'mystery', b'thriller', b'at', b'the',\n",
              "        b'same', b'time', b'Nice', b'combination', b'of', b'strange',\n",
              "        b\"'dogma'\", b'style', b'of', b'telling', b'the', b'story',\n",
              "        b'together', b'with', b'good', b'music', b'and', b'great',\n",
              "        b'actors', b'But', b'unfortunately', b\"there's\", b'no', b\"'the\",\n",
              "        b\"end'\", b'As', b'for', b'me', b\"it's\", b'unacceptable', b'I',\n",
              "        b'was', b'thinking', b'how', b'it', b'will', b'be', b'possibl',\n",
              "        b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>', b'<pad>',\n",
              "        b'<pad>', b'<pad>', b'<pad>']], dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7BiHFlmKbmc",
        "outputId": "66200526-5a89-4625-803a-e7a93878d641",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_batch.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([8, 60])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDzWKoZBJhZD",
        "outputId": "d9c4b889-6690-438f-84ef-49b25eb1761a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_batch"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(8,), dtype=int64, numpy=array([1, 0, 0, 0, 1, 0, 0, 1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOcnC27qtPNz"
      },
      "source": [
        "def encode_words(X_batch, y_batch):\n",
        "    return table.lookup(X_batch), y_batch"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xiw9wubPESF"
      },
      "source": [
        "train_set = datasets[\"train\"].repeat().batch(32).map(preprocess)\n",
        "train_set = train_set.map(encode_words).prefetch(1)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_n1CZ6xtUiL",
        "outputId": "be705b1e-c58c-4003-e226-3b7f9ecfc19e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "source": [
        "for X_batch, y_batch in train_set.take(1):\n",
        "    print(X_batch)\n",
        "    print(y_batch)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[  22   11   28 ...    0    0    0]\n",
            " [   6   21   70 ...    0    0    0]\n",
            " [4099 6881    1 ...    0    0    0]\n",
            " ...\n",
            " [  22   12  118 ...  331 1047    0]\n",
            " [1757 4101  451 ...    0    0    0]\n",
            " [3365 4392    6 ...    0    0    0]], shape=(32, 60), dtype=int64)\n",
            "tf.Tensor([0 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 0 0 0], shape=(32,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL62blW-tWUT"
      },
      "source": [
        "embed_size = 128\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Embedding(vocab_size + num_oov_buckets, embed_size,\n",
        "                           mask_zero=True, # not shown in the book\n",
        "                           input_shape=[None]),\n",
        "    keras.layers.GRU(128, return_sequences=True),\n",
        "    keras.layers.GRU(128),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIUJlb5uR2Sg",
        "outputId": "84673993-fc13-49ba-a9a1-e8aef004acaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, None, 128)         1408000   \n",
            "_________________________________________________________________\n",
            "gru_12 (GRU)                 (None, None, 128)         99072     \n",
            "_________________________________________________________________\n",
            "gru_13 (GRU)                 (None, 128)               99072     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,606,273\n",
            "Trainable params: 1,606,273\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10EE-4H-R6oX",
        "outputId": "53e38c9a-d78f-43eb-b84a-34603fce1936",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "history = model.fit(train_set, steps_per_epoch=train_size // 32, epochs=5)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5418 - accuracy: 0.7171\n",
            "Epoch 2/5\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.3471 - accuracy: 0.8561\n",
            "Epoch 3/5\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1855 - accuracy: 0.9349\n",
            "Epoch 4/5\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1334 - accuracy: 0.9537\n",
            "Epoch 5/5\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.1079 - accuracy: 0.9615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rh8iVc1tZhL"
      },
      "source": [
        "test_set = datasets[\"test\"].repeat().batch(32).map(preprocess)\n",
        "test_set = test_set.map(encode_words).prefetch(1)\n",
        "\n",
        "a = model.predict(test_set.take(1))"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyiLpjt5t8-I",
        "outputId": "d837f1ce-49aa-4bdf-c1db-9982cbc68b92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "source": [
        "for X_batch, y_batch in test_set.take(1):\n",
        "    print(X_batch)\n",
        "    print(y_batch)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[  135    26    77 ...     0     0     0]\n",
            " [   74 10791   776 ...     0     0     0]\n",
            " [ 3078   755 10210 ...     0     0     0]\n",
            " ...\n",
            " [ 5703  9425  8036 ...     0     0     0]\n",
            " [  274     6    21 ...     0     0     0]\n",
            " [    6    98     9 ...     0     0     0]], shape=(32, 64), dtype=int64)\n",
            "tf.Tensor([1 1 0 0 1 1 1 1 0 1 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 1 0 0 0 1 1 1], shape=(32,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGGT9iCQviNn"
      },
      "source": [
        "b = table.lookup(tf.constant([b\"The movie is so bad and wasting my time\".split()]))"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWey-vTQwme9",
        "outputId": "d6d9051e-bb6d-4873-aeba-88dd2d32838d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.predict(b)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.17164907]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCEORt7Kwq89"
      },
      "source": [
        "b = table.lookup(tf.constant([b\"The movie is awesome. I can watch it again and again\".split()]))"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsxCxUULgSgk",
        "outputId": "a427d80b-8bc9-4bd6-af90-d098324b3fce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.predict(b)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9461711]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKDPfrUVgXV-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}